
<!doctype html>
<!--[if lt IE 7]> <html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if IE 7]>    <html class="no-js lt-ie9 lt-ie8" lang="en"> <![endif]-->
<!--[if IE 8]>    <html class="no-js lt-ie9" lang="en"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"> <!--<![endif]-->
<head>
	<meta charset="utf-8">

	<title>Look, Listen and Learn - A Multimodal LSTM for Speaker Identiﬁcation | Yongtao Hu</title>

	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<script src="/js/vendor/modernizr-2.5.3.min.js"></script>

	<script src="//ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js"></script>
	<script>window.jQuery || document.write('<script src="/js/vendor/jquery-1.7.2.min.js"><\/script>')</script>

	<script src="/js/vendor/spamspan.min.js"></script>
	<script src="/js/vendor/prettify.js"></script>

	<link rel="stylesheet" href="/plugins/social-media-widget/social_widget.css?ver=3.9.1">
	<link rel="stylesheet" href="/glyphicons/css/glyphicons.css">
	<link rel="stylesheet" href="/css/bootstrap.css">
	<link rel="stylesheet" href="/css/bootstrap-responsive.css">
	<link rel="stylesheet" href="/css/app.css">
	<script type='text/javascript' src='/js/plugins.js'></script>
	<script type='text/javascript' src='/js/main.js'></script>
	<link rel="canonical" href="http://herohuyongtao.github.io/publications/speaker-following-subtitles/">
	<link rel="shortcut icon" href="http://herohuyongtao.github.io/images/logo.ico">
</head>

<body class="page page-id-62 page-parent page-child parent-pageid-25 page-template-default top-navbar">
  <!--[if lt IE 7]><div class="alert">Your browser is <em>ancient!</em> <a href="http://browsehappy.com/">Upgrade to a different browser</a> or <a href="http://www.google.com/chromeframe/?redirect=true">install Google Chrome Frame</a> to experience this site.</div><![endif]-->

    <header id="banner" class="navbar navbar-fixed-top" role="banner">
		<div class="navbar-inner">
			<div class="container">
				<a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
				</a>
				<a class="brand" href="http://herohuyongtao.github.io/">
					Yongtao Hu
				</a>
				<nav id="nav-main" class="nav-collapse" role="navigation">
					<ul class="nav">
						<li class="menu-home"><a href="/">Home</a></li>
						<li class="menu-publications active active"><a href="/research/">Research</a></li>
						<li class="menu-cv"><a href="/cv/">Resume</a></li>
						<li class="menu-news"><a href="/news/">News</a></li>
						<li class="menu-links"><a href="/links/">Links</a></li>
					</ul>
				</nav>
			</div>
		</div>
	</header>

    <div id="wrap" class="container" role="document">
		<div id="content" class="row">
			<div id="main" class="span12" role="main">
				<div class="page-header">
					<h1>Look, Listen and Learn - A Multimodal LSTM for Speaker Identiﬁcation</h1>
				</div>

				<p style="text-align: center;">
				    <a href="http://www.jimmyren.com/">Jimmy SJ. Ren</a><sup>1</sup>
				    <a href="http://herohuyongtao.github.io/">Yongtao Hu</a><sup>2</sup>
				    <a href="http://gdriv.es/yuwing">Yu-Wing Tai</a><sup>1</sup>
				    <a href="http://i.cs.hku.hk/~cwang/">Chuan Wang</a><sup>2</sup>
				    <a href="http://lxu.me/">Li Xu</a><sup>1</sup>
				    <a href="https://www.linkedin.com/in/wenxiu-sun-bb6b292b">Wenxiu Sun</a><sup>1</sup>
				    <a href="http://www.yan-qiong.com/">Qiong Yan</a><sup>1</sup>
				</p>
				<p style="text-align: center;">
					<sup>1</sup>
					SenseTime Group Limited, Hong Kong
					&nbsp;&nbsp;&nbsp;&nbsp;
					<sup>2</sup>
					The University of Hong Kong, Hong Kong
				</p>
				<p style="text-align: center;">
					<em>The 30th AAAI Conference on Artificial Intelligence (AAAI 2016)</em>
				</p>
				<div style="text-align: center;">
					<img class="size-full wp-image-96 " style="margin: 1em 0; height: auto;" title="Teaser image" src="teaser.png" alt="" width="720" />
					<br />
					Figure: (a) Face sequence with different kinds of degradations and variations. Using the previous CNN methods cannot recognize the speakers correctly. In contrast, the speakers can be successfully recognized by our LSTM in both single-modal and multimodal settings. (b) Our multimodal LSTM is robust to both image degradation and distractors. Yellow bounding boxes are the speakers. Red bounding boxes are the non-speakers, the distractors.
				</div>
				<hr />
				<h2>Abstract</h2>
				<p>
					Speaker identiﬁcation refers to the task of localizing the face of a person who has the same identity as the ongoing voice in a video. This task not only requires collective perception over both visual and auditory signals, the robustness to handle severe quality degradations and unconstrained content variations are also indispensable. In this paper, we describe a novel multimodal Long Short-Term Memory (LSTM) architecture which seamlessly uniﬁes both visual and auditory modalities from the beginning of each sequence input. The key idea is to extend the conventional LSTM by not only sharing weights across time steps, but also sharing weights across modalities. We show that modeling the temporal dependency across face and voice can signiﬁcantly improve the robustness to content quality degradations and variations. We also found that our multimodal LSTM is robustness to distractors, namely the non-speaking identities. We applied our multimodal LSTM to The Big Bang Theory dataset and showed that our system outperforms the state-of-the-art systems in speaker identification with lower false alarm rate and higher recognition accuracy.
				</p>
				<h2>Downloads</h2>
				<ul class="unstyled">
					<li><em class="icon-file"></em> <a href="paper.pdf">Paper</a> (PDF, 0.5 MB)</li>
					<li><em class="icon-turtle"></em> <a href="https://github.com/jimmy-ren/lstm_speaker_naming_aaai16">Source code & dataset</a> (MATLAB, hosted on Github)</li>
					<li><em class="icon-turtle"></em> <a href="https://github.com/jimmy-ren/vLSTM">Updated version of multimodal LSTM and more applications</a> (MATLAB, hosted on Github)</li>
					<!-- <li><em class="icon-facetime-video"></em> <a href="supp_video.mp4">Supplementary video</a> (MP4, 9.5 MB)</li>
					<-->
				</ul>
				<h2>Bibtex</h2>
				<pre>
@inproceedings{ren2016look,
  title={{Look, Listen and Learn - A Multimodal LSTM for Speaker Identification}},
  author={Ren, Jimmy SJ. and Hu, Yongtao and Tai, Yu-Wing and Wang, Chuan and Xu, Li and Sun, Wenxiu and Yan, Qiong},
  booktitle={Proceedings of the 30th AAAI Conference on Artificial Intelligence},
  pages={3581--3587},
  year={2016}
}</pre> <!-- put </pre> on this line to avoid new unwanted line breaks after bibtex -->
			</div><!-- /#main -->
		</div><!-- /#content -->
    </div><!-- /#wrap -->

	<footer id="content-info" class="container" role="contentinfo">
		<table width="100%">
			<tr>
				<td>
					<p class="copy"><small>&copy; 2014-2016 Yongtao Hu</small></p>
				</td>
				<td style="text-align:center">
					<p class="copy"><small>Last updated on 02/17/2016</small></p>
				</td>
				<td style="text-align:right">
					<a href="https://SiteStates.com" title="Site access statistics">
						<img src="https://SiteStates.com/show/image/31385.jpg" border="0" />
					</a>
				</td>
			</tr>
		</table>
	</footer>

	<!-- From http://stackoverflow.com/a/11668413/72470 -->
	<script>
	  !function ($) {
		$(function(){
		  window.prettyPrint && prettyPrint()
		})
	  }(window.jQuery)
	</script>
</body>
</html>
